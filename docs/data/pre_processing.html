<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.4" />
<title>k_seq.data.pre_processing API documentation</title>
<meta name="description" content="This module contains the methods for data input and output" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>k_seq.data.pre_processing</code> module</h1>
</header>
<section id="section-intro">
<p>This module contains the methods for data input and output</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;
This module contains the methods for data input and output
&#34;&#34;&#34;

import numpy as np
import pandas as pd
from . import io


class SequencingSample:

    &#34;&#34;&#34;
    This class defines and describe the experimental samples sequenced in k-seq experiments
    &#34;&#34;&#34;

    def __init__(self, file_root, sample_name, x_value, silent=True, name_pattern=None):
        &#34;&#34;&#34;
        initialize a SequencingSample instance by reading single count file
        :param file_root: root directory of the sample folder
        :param sample_name: the name (without directory) of the sample
        :param corresponding x_value for the sample. If string, will automatically inspect the domain with the name
        :param silent: [Optional] boolean.
        :param name_pattern: optional. pattern to extract metadata. pattern rules: [...] to include the region of
               sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
               [,digit] will convert the domain value to float in applicable, otherwise, string
               e.g. R4B-1250A_S16_counts.txt with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
               will return SequencingSample.metadata = {
                                    &#39;exp_rep&#39;: &#39;B&#39;,
                                    &#39;concentration&#39;: 1250.0,
                                    &#39;seq_rep&#39;: &#39;A&#39;,
                                    &#39;id&#39;: 16.0
                                 }
        &#34;&#34;&#34;
        import datetime

        self.metadata = {}
        if file_root[-1] != &#39;/&#39;:
            file_root += &#39;/&#39;
        self.metadata[&#39;file_dirc&#39;] = &#39;{}{}&#39;.format(file_root, sample_name)
        self.unique_seqs, self.total_counts, self.sequences = io.read_count_file(self.metadata[&#39;file_dirc&#39;])

        if name_pattern:
            metadata = extract_sample_metadata(sample_name=sample_name, name_pattern=name_pattern)
            self.name = metadata.pop(&#39;name&#39;, None)
            self.metadata.update(metadata)
        else:
            self.name = sample_name

        if &#39;input&#39; in self.name or &#39;Input&#39; in self.name:
            self.sample_type = &#39;input&#39;
        else:
            self.sample_type = &#39;reacted&#39;

        if self.sample_type == &#39;input&#39;:
            self.x_value = np.nan
        else:
            if type(x_value) == str:
                self.x_value = self.metadata[x_value]
            else:
                self.x_value = x_value

        self.metadata[&#39;timestamp&#39;] = str(datetime.datetime.now())
        if not silent:
            print(&#34;Sample {} imported.&#34;.format(self.name))

    def survey_spike_in(self, spike_in, max_dist_to_survey=10, silent=True):
        &#34;&#34;&#34;
        This method will survey the number of spike-in sequences in the sample, with edit distance to the center
        spike-in sequence
        Following attributes will be added to the instance:
        - spike_in: dict, {
            spike_in_counts: list of int with length max_dist_to_survey + 1, number of total counts with distance i to
                             the center spike-in sequence
            spike_in: string, spike_in sequence
          }
        :param spike_in: string, the sequence of spike-in, consider as the center sequence
        :param max_dist_to_survey: int, the maximum distance to survey
        :return: None
        &#34;&#34;&#34;
        import Levenshtein

        self.spike_in = {}
        self.spike_in[&#39;spike_in_counts&#39;] = np.array([0 for _ in range(max_dist_to_survey + 1)])
        self.spike_in[&#39;spike_in&#39;] = spike_in
        for seq in self.sequences.keys():
            dist = Levenshtein.distance(spike_in, seq)
            if dist &lt;= max_dist_to_survey:
                self.spike_in[&#39;spike_in_counts&#39;][dist] += self.sequences[seq]
        if not silent:
            print(&#34;Survey spike-in counts for sample {}. Done.&#34;.format(self.name))

    def get_quant_factor(self, spike_in_amount, max_dist=0, silent=True):
        &#34;&#34;&#34;
        Add quant_factor and quant_factor_max_dist attributes to SequencingSample
        quant_factor here is defined as spike_in_amount/total_counts/np.sum(spike_in_counts[:max_dist + 1])
        :param max_dist:
        :param spike_in_amount:
        :return:
        &#34;&#34;&#34;

        self.quant_factor = spike_in_amount * self.total_counts / np.sum(self.spike_in[&#39;spike_in_counts&#39;][:max_dist + 1])
        self.spike_in[&#39;quant_factor_max_dist&#39;] = max_dist
        self.spike_in[&#39;spike_in_amount&#39;] = spike_in_amount

        if not silent:
            print(&#34;Calculate quant-factor for sample {}. Done.&#34;.format(self.name))


def extract_sample_metadata(sample_name, name_pattern):
    &#34;&#34;&#34;
    Auxiliary function to extract sample information from sample_name, provided name_pattern
    :param sample_name: string, sample name
    :param name_pattern: pattern to extract metadata.
                         pattern rules:
                             [...] to include the region of sample_name,
                             {domain_name[, digit]} to indicate region of domain to extract as metadata, including
                             [,digit] will convert the domain value to number, otherwise, string
                         e.g. R4B-1250A_S16_counts.txt
                              with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
                              will return SequencingSample.metadata = {
                                              &#39;exp_rep&#39;: &#39;B&#39;,
                                              &#39;concentration&#39;: 1250.0,
                                              &#39;seq_rep&#39;: &#39;A&#39;,
                                              &#39;id&#39;: 16.0
                                           }
    :return: metadata
    &#34;&#34;&#34;
    import re

    def divide_string(string):
        def letter_label(letter):
            if letter.isdigit():
                return 0
            elif letter.isupper():
                return 1
            else:
                return 2

        label = [letter_label(letter) for letter in string]

        split_ix = [-1] + [ix for ix in range(len(string) - 1) if label[ix] != label[ix + 1]] + [len(string)]
        return [string[split_ix[i] + 1: split_ix[i + 1] + 1] for i in range(len(split_ix) - 1)]

    def extract_domain_name(domain):
        digit_ix = max(domain.find(&#39;,digit&#39;), domain.find(&#39;, digit&#39;), domain.find(&#39;,d&#39;), domain.find(&#39;, &#39;))
        if digit_ix &gt; 0:
            return domain[:digit_ix], True
        elif domain != &#39;&#39;:
            return domain, False
        else:
            return None

    metadata = {}       # dict to save extracted values
    # Anchor the position of brackets and curly braces in name_pattern
    brackets = [name_pattern.find(&#39;[&#39;), name_pattern.find(&#39;]&#39;)]
    metadata[&#39;name&#39;] = sample_name[brackets[0]:len(sample_name) + brackets[1] - len(name_pattern) + 1]
    curly_braces = [(0, brackets[0])] + \
                   list(zip([instance.start() for instance in re.finditer(string=name_pattern, pattern=&#39;{&#39;)],
                           [instance.start() for instance in re.finditer(string=name_pattern, pattern=&#39;}&#39;)])) + \
                   [(brackets[1], brackets[1]), (len(name_pattern) - 1, len(name_pattern) - 1)]
    sample_start = 0
    brace_ix = 1
    while brace_ix &lt; len(curly_braces) and curly_braces[brace_ix][0] != curly_braces[brace_ix][1]:
        # get prefix
        prefix = name_pattern[curly_braces[brace_ix - 1][1] + 1: curly_braces[brace_ix][0]]
        domain_list = [extract_domain_name(name_pattern[curly_braces[brace_ix][0] + 1: curly_braces[brace_ix][1]])]
        # anchor the end of compound braces, e.g. {}{}
        while curly_braces[brace_ix][1] + 1 == curly_braces[brace_ix + 1][0]:
            brace_ix += 1
            if curly_braces[brace_ix][0] != curly_braces[brace_ix][1]:
                domain_list.append(
                    extract_domain_name(name_pattern[curly_braces[brace_ix][0] + 1: curly_braces[brace_ix][1]]))
        # get postfix
        postfix = name_pattern[curly_braces[brace_ix][1] + 1: curly_braces[brace_ix + 1][0]]
        # get region to extract
        start_ix = sample_name.find(prefix, sample_start) + len(prefix)
        sample_start = start_ix
        end_ix = sample_name.find(postfix, sample_start)
        sample_start = end_ix
        if len(domain_list) &gt; 1:
            domain_values = divide_string(sample_name[start_ix:end_ix])
        else:
            domain_values = [sample_name[start_ix:end_ix]]
        for ix, domain in enumerate(domain_list):
            if domain[1]:
                try:
                    metadata[domain[0]] = float(domain_values[ix])
                except:
                    metadata[domain[0]] = domain_values[ix]
            else:
                metadata[domain[0]] = domain_values[ix]
        brace_ix += 1
    return metadata


def get_file_list(file_root, pattern=None):
    &#34;&#34;&#34;
    list all files under the given file root
    :param file_root: root directory
    :param pattern: optional, file name pattern to identify count files
    :return: a list of file names
    &#34;&#34;&#34;
    import glob
    if not pattern:
        pattern = &#39;&#39;
    sample_list = [file_name[file_name.rfind(&#39;/&#39;)+1:]
                   for file_name in glob.glob(&#34;{}/*{}*&#34;.format(file_root, pattern))
                   if not &#39;@&#39; in file_name]
    sample_list.sort()
    return sample_list


def load_count_files(file_root, x_values, sample_list=None, pattern=None, name_pattern=None, sort_fn=None, black_list=[], silent=True):
    &#34;&#34;&#34;
    load all count files under file_root if comply with pattern. A list of SequencingSample will return, each includes
        self.file_dirc: full directory to the count file
        self.name: sample_name or indicated by name_pattern
        self.unqiue_seqs: number of unique sequences reported in count file
        self.total_counts: number of total counts reported in count file
        self.sequences: a dictionary of {seq: count} reported in count file
        self.sample_type: type of sample, either be &#39;input&#39; or &#39;reacted&#39;
    :param file_root: root directory
    :param x_values: string or a list of floats. if string, will use it as domain name to extract x_value for each sample
                     if a list of floats, it should have same length and order as the sample list
    :param pattern: optional, file name pattern to identify count files
    :param name_pattern: optional. pattern to extract metadata. pattern rules: [...] to include the region of
                         sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
                         [,digit] will convert the domain value to number, otherwise, string
                         e.g. R4B-1250A_S16_counts.txt with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
                         will return SequencingSample.metadata = {
                                              &#39;exp_rep&#39;: &#39;B&#39;,
                                              &#39;concentration&#39;: 1250.0,
                                              &#39;seq_rep&#39;: &#39;A&#39;,
                                              &#39;id&#39;: 16.0
                                           }
    :param sort_fn: optional, callable to sort sample order
    :param black_list: name of sample files that will be excluded in loading
    :param slient: boolean, false: print calculation progress to the screen
    :return: sample_set: a list of SequencingSample class
    &#34;&#34;&#34;
    if sample_list is None:
        sample_list = get_file_list(file_root=file_root, pattern=pattern)
        print(&#34;NOTICE: no sample_list is given, samples will extract automaticall from file_root.&#34;)
        if type(x_values) != str:
            raise Exception(&#34;No sample_list is given, please indicate domain name instead of list of real values to extract x_values&#34;)
    sample_set = []
    if type(x_values) == str:
        x_values = [x_values for _ in sample_list]
    for sample_ix,sample_name in enumerate(sample_list):
        if sample_name not in black_list:
            sample = SequencingSample(file_root=file_root,
                                      sample_name=sample_name,
                                      x_value=x_values[sample_ix],
                                      name_pattern=name_pattern,
                                      silent=silent)
            sample_set.append(sample)
    if sort_fn:
        sample_set.sort(key=sort_fn)
    return sample_set

def get_quant_factors(sample_set, spike_in=&#39;AAAAACAAAAACAAAAACAAA&#39;, max_dist=2, max_dist_to_survey=10,
                      spike_in_amounts=None, manual_quant_factor=None, silent=True):
    &#34;&#34;&#34;
    Assign/calculate quant_factor for SequencingSet instances in sample_set
    :param sample_set:
    :param spike_in:
    :param max_dist:
    :param max_dist_to_survey:
    :param spike_in_amounts:
    :param manual_quant_factor:
    :param silent:
    :return:
    &#34;&#34;&#34;
    if manual_quant_factor:
        for sample_ix, sample in enumerate(sample_set):
            sample.quant_factor = manual_quant_fasctor[sample_ix]
    else:
        for sample_ix, sample in enumerate(sample_set):
            sample.survey_spike_in(spike_in = spike_in, max_dist_to_survey=max_dist_to_survey, silent=silent)
            sample.get_quant_factor(spike_in_amount = spike_in_amounts[sample_ix], max_dist=max_dist)

    return sample_set


class SequenceSet:
    &#34;&#34;&#34;
    This class containing the dataset of valid sequences aligned from a list of SequencingSample
    &#34;&#34;&#34;

    def __init__(self, sample_set, remove_spike_in=True, note=None):
        &#34;&#34;&#34;
        Convert a list of SequencingSample objects to a SequenceSet object. A typical SequenceSet object includes:
            self.input_seq_num: number of unique sequences in all &#34;input&#34; samples
            self.reacted_seq_num number of unique sequences in all &#34;reacted&#34; samples
            self.valid_seq_num: number of valid unqiue sequences that detected in at least one &#34;input&#34; sample and one
                                &#34;reacted&#34; sample
            self.sample_info: a list of dictionaries, containing the information from original samples
            self.count_table: a pandas.DataFrame object of valid sequences and their original counts in samples
            self.valid_seq_remove_spike_in: Boolean. If True, sequences considered as spike-in will not include in counting
            self.note: Optional. Addtional notes regarding to the dataset
        :param sample_set: a list of SequencingSample objects to convert
        :param remove_spike_in: Boolean. See above
        :param note: Optional. See above
        :return: A SequenceSet object
        &#34;&#34;&#34;
        import datetime
        import Levenshtein

        # find valid sequence set
        input_seq_set = set()
        reacted_seq_set = set()

        if remove_spike_in:
            for sample in sample_set:
                if sample.sample_type == &#39;input&#39;:
                    input_seq_set.update([
                        seq for seq in sample.sequences.keys()
                        if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                    ])
                elif sample.sample_type == &#39;reacted&#39;:
                    reacted_seq_set.update([
                        seq for seq in sample.sequences.keys()
                        if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                    ])
        else:
            for sample in sample_set:
                if sample.sample_type == &#39;input&#39;:
                    input_seq_set.update(list(sample.sequences.keys()))
                elif sample.sample_type == &#39;reacted&#39;:
                    reacted_seq_set.update(list(sample.sequences.keys()))

        valid_set = input_seq_set &amp; reacted_seq_set
        self.dataset_info = {
            &#39;input_seq_num&#39;: len(input_seq_set),
            &#39;reacted_seq_num&#39;: len(reacted_seq_set),
            &#39;valid_seq_num&#39;: len(valid_set),
            &#39;remove_spike_in&#39;: remove_spike_in
        }
        if note:
            self.dataset_info[&#39;note&#39;] = note

        # preserve sample info
        self.sample_info = {}
        for sample in sample_set:
            sample_info_dict = sample.__dict__.copy()
            sequences = sample_info_dict.pop(&#39;sequences&#39;, None)
            self.sample_info[sample.name] = {
                &#39;valid_seqs_num&#39;: np.sum([1 for seq in sequences.keys() if seq in valid_set]),
                &#39;valid_seqs_counts&#39;: np.sum([seq[1] for seq in sequences.items() if seq[0] in valid_set])
            }
            self.sample_info[sample.name].update(sample_info_dict)

        # create valid sequence table
        self.count_table = pd.DataFrame(index=list(valid_set), columns=[sample.name for sample in sample_set])
        for seq in valid_set:
            for sample in sample_set:
                if seq in sample.sequences.keys():
                    self.count_table.loc[seq, sample.name] = sample.sequences[seq]

        self.dataset_info[&#39;timestamp&#39;] = str(datetime.datetime.now())

    def get_reacted_frac(self, input_average=&#39;median&#39;, black_list=None, inplace=True):

        if not black_list:
            black_list = []
        input_samples = [sample[0] for sample in self.sample_info.items()
                         if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;input&#39;]
        reacted_samples = [sample[0] for sample in self.sample_info.items()
                           if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;reacted&#39;]
        reacted_frac_table = pd.DataFrame(index=self.count_table.index, columns=reacted_samples)
        reacted_frac_table.input_avg_type = input_average
        reacted_frac_table.col_x_values = [self.sample_info[sample][&#39;x_value&#39;] for sample in reacted_frac_table.columns]

        if input_average == &#39;median&#39;:
            input_amount_avg = np.nanmedian(np.array([
                list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                self.sample_info[sample][&#39;quant_factor&#39;])
                for sample in input_samples
            ]), axis=0)
        elif input_average == &#39;mean&#39;:
            input_amount_avg = np.nanmean(np.array([
                list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                     self.sample_info[sample][&#39;quant_factor&#39;])
                for sample in input_samples
            ]), axis=0)
        else:
            raise Exception(&#34;Error: input_average should be &#39;median&#39; or &#39;mean&#39;&#34;)

        reacted_frac_table.input_avg = input_amount_avg
        for sample in reacted_samples:
            reacted_frac_table[sample] = (
                self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                self.sample_info[sample][&#39;quant_factor&#39;]
            )/reacted_frac_table.input_avg

        if inplace:
            self.reacted_frac_table = reacted_frac_table
        else:
            return reacted_frac_table</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="k_seq.data.pre_processing.extract_sample_metadata"><code class="name flex">
<span>def <span class="ident">extract_sample_metadata</span></span>(<span>sample_name, name_pattern)</span>
</code></dt>
<dd>
<section class="desc"><p>Auxiliary function to extract sample information from sample_name, provided name_pattern
:param sample_name: string, sample name
:param name_pattern: pattern to extract metadata.
pattern rules:
[&hellip;] to include the region of sample_name,
{domain_name[, digit]} to indicate region of domain to extract as metadata, including
[,digit] will convert the domain value to number, otherwise, string
e.g. R4B-1250A_S16_counts.txt
with pattern = "R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt"
will return SequencingSample.metadata = {
'exp_rep': 'B',
'concentration': 1250.0,
'seq_rep': 'A',
'id': 16.0
}
:return: metadata</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def extract_sample_metadata(sample_name, name_pattern):
    &#34;&#34;&#34;
    Auxiliary function to extract sample information from sample_name, provided name_pattern
    :param sample_name: string, sample name
    :param name_pattern: pattern to extract metadata.
                         pattern rules:
                             [...] to include the region of sample_name,
                             {domain_name[, digit]} to indicate region of domain to extract as metadata, including
                             [,digit] will convert the domain value to number, otherwise, string
                         e.g. R4B-1250A_S16_counts.txt
                              with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
                              will return SequencingSample.metadata = {
                                              &#39;exp_rep&#39;: &#39;B&#39;,
                                              &#39;concentration&#39;: 1250.0,
                                              &#39;seq_rep&#39;: &#39;A&#39;,
                                              &#39;id&#39;: 16.0
                                           }
    :return: metadata
    &#34;&#34;&#34;
    import re

    def divide_string(string):
        def letter_label(letter):
            if letter.isdigit():
                return 0
            elif letter.isupper():
                return 1
            else:
                return 2

        label = [letter_label(letter) for letter in string]

        split_ix = [-1] + [ix for ix in range(len(string) - 1) if label[ix] != label[ix + 1]] + [len(string)]
        return [string[split_ix[i] + 1: split_ix[i + 1] + 1] for i in range(len(split_ix) - 1)]

    def extract_domain_name(domain):
        digit_ix = max(domain.find(&#39;,digit&#39;), domain.find(&#39;, digit&#39;), domain.find(&#39;,d&#39;), domain.find(&#39;, &#39;))
        if digit_ix &gt; 0:
            return domain[:digit_ix], True
        elif domain != &#39;&#39;:
            return domain, False
        else:
            return None

    metadata = {}       # dict to save extracted values
    # Anchor the position of brackets and curly braces in name_pattern
    brackets = [name_pattern.find(&#39;[&#39;), name_pattern.find(&#39;]&#39;)]
    metadata[&#39;name&#39;] = sample_name[brackets[0]:len(sample_name) + brackets[1] - len(name_pattern) + 1]
    curly_braces = [(0, brackets[0])] + \
                   list(zip([instance.start() for instance in re.finditer(string=name_pattern, pattern=&#39;{&#39;)],
                           [instance.start() for instance in re.finditer(string=name_pattern, pattern=&#39;}&#39;)])) + \
                   [(brackets[1], brackets[1]), (len(name_pattern) - 1, len(name_pattern) - 1)]
    sample_start = 0
    brace_ix = 1
    while brace_ix &lt; len(curly_braces) and curly_braces[brace_ix][0] != curly_braces[brace_ix][1]:
        # get prefix
        prefix = name_pattern[curly_braces[brace_ix - 1][1] + 1: curly_braces[brace_ix][0]]
        domain_list = [extract_domain_name(name_pattern[curly_braces[brace_ix][0] + 1: curly_braces[brace_ix][1]])]
        # anchor the end of compound braces, e.g. {}{}
        while curly_braces[brace_ix][1] + 1 == curly_braces[brace_ix + 1][0]:
            brace_ix += 1
            if curly_braces[brace_ix][0] != curly_braces[brace_ix][1]:
                domain_list.append(
                    extract_domain_name(name_pattern[curly_braces[brace_ix][0] + 1: curly_braces[brace_ix][1]]))
        # get postfix
        postfix = name_pattern[curly_braces[brace_ix][1] + 1: curly_braces[brace_ix + 1][0]]
        # get region to extract
        start_ix = sample_name.find(prefix, sample_start) + len(prefix)
        sample_start = start_ix
        end_ix = sample_name.find(postfix, sample_start)
        sample_start = end_ix
        if len(domain_list) &gt; 1:
            domain_values = divide_string(sample_name[start_ix:end_ix])
        else:
            domain_values = [sample_name[start_ix:end_ix]]
        for ix, domain in enumerate(domain_list):
            if domain[1]:
                try:
                    metadata[domain[0]] = float(domain_values[ix])
                except:
                    metadata[domain[0]] = domain_values[ix]
            else:
                metadata[domain[0]] = domain_values[ix]
        brace_ix += 1
    return metadata</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.get_file_list"><code class="name flex">
<span>def <span class="ident">get_file_list</span></span>(<span>file_root, pattern=None)</span>
</code></dt>
<dd>
<section class="desc"><p>list all files under the given file root
:param file_root: root directory
:param pattern: optional, file name pattern to identify count files
:return: a list of file names</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_file_list(file_root, pattern=None):
    &#34;&#34;&#34;
    list all files under the given file root
    :param file_root: root directory
    :param pattern: optional, file name pattern to identify count files
    :return: a list of file names
    &#34;&#34;&#34;
    import glob
    if not pattern:
        pattern = &#39;&#39;
    sample_list = [file_name[file_name.rfind(&#39;/&#39;)+1:]
                   for file_name in glob.glob(&#34;{}/*{}*&#34;.format(file_root, pattern))
                   if not &#39;@&#39; in file_name]
    sample_list.sort()
    return sample_list</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.get_quant_factors"><code class="name flex">
<span>def <span class="ident">get_quant_factors</span></span>(<span>sample_set, spike_in=&#39;AAAAACAAAAACAAAAACAAA&#39;, max_dist=2, max_dist_to_survey=10, spike_in_amounts=None, manual_quant_factor=None, silent=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Assign/calculate quant_factor for SequencingSet instances in sample_set
:param sample_set:
:param spike_in:
:param max_dist:
:param max_dist_to_survey:
:param spike_in_amounts:
:param manual_quant_factor:
:param silent:
:return:</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_quant_factors(sample_set, spike_in=&#39;AAAAACAAAAACAAAAACAAA&#39;, max_dist=2, max_dist_to_survey=10,
                      spike_in_amounts=None, manual_quant_factor=None, silent=True):
    &#34;&#34;&#34;
    Assign/calculate quant_factor for SequencingSet instances in sample_set
    :param sample_set:
    :param spike_in:
    :param max_dist:
    :param max_dist_to_survey:
    :param spike_in_amounts:
    :param manual_quant_factor:
    :param silent:
    :return:
    &#34;&#34;&#34;
    if manual_quant_factor:
        for sample_ix, sample in enumerate(sample_set):
            sample.quant_factor = manual_quant_fasctor[sample_ix]
    else:
        for sample_ix, sample in enumerate(sample_set):
            sample.survey_spike_in(spike_in = spike_in, max_dist_to_survey=max_dist_to_survey, silent=silent)
            sample.get_quant_factor(spike_in_amount = spike_in_amounts[sample_ix], max_dist=max_dist)

    return sample_set</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.load_count_files"><code class="name flex">
<span>def <span class="ident">load_count_files</span></span>(<span>file_root, x_values, sample_list=None, pattern=None, name_pattern=None, sort_fn=None, black_list=[], silent=True)</span>
</code></dt>
<dd>
<section class="desc"><p>load all count files under file_root if comply with pattern. A list of SequencingSample will return, each includes
self.file_dirc: full directory to the count file
self.name: sample_name or indicated by name_pattern
self.unqiue_seqs: number of unique sequences reported in count file
self.total_counts: number of total counts reported in count file
self.sequences: a dictionary of {seq: count} reported in count file
self.sample_type: type of sample, either be 'input' or 'reacted'
:param file_root: root directory
:param x_values: string or a list of floats. if string, will use it as domain name to extract x_value for each sample
if a list of floats, it should have same length and order as the sample list
:param pattern: optional, file name pattern to identify count files
:param name_pattern: optional. pattern to extract metadata. pattern rules: [&hellip;] to include the region of
sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
[,digit] will convert the domain value to number, otherwise, string
e.g. R4B-1250A_S16_counts.txt with pattern = "R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt"
will return SequencingSample.metadata = {
'exp_rep': 'B',
'concentration': 1250.0,
'seq_rep': 'A',
'id': 16.0
}
:param sort_fn: optional, callable to sort sample order
:param black_list: name of sample files that will be excluded in loading
:param slient: boolean, false: print calculation progress to the screen
:return: sample_set: a list of SequencingSample class</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def load_count_files(file_root, x_values, sample_list=None, pattern=None, name_pattern=None, sort_fn=None, black_list=[], silent=True):
    &#34;&#34;&#34;
    load all count files under file_root if comply with pattern. A list of SequencingSample will return, each includes
        self.file_dirc: full directory to the count file
        self.name: sample_name or indicated by name_pattern
        self.unqiue_seqs: number of unique sequences reported in count file
        self.total_counts: number of total counts reported in count file
        self.sequences: a dictionary of {seq: count} reported in count file
        self.sample_type: type of sample, either be &#39;input&#39; or &#39;reacted&#39;
    :param file_root: root directory
    :param x_values: string or a list of floats. if string, will use it as domain name to extract x_value for each sample
                     if a list of floats, it should have same length and order as the sample list
    :param pattern: optional, file name pattern to identify count files
    :param name_pattern: optional. pattern to extract metadata. pattern rules: [...] to include the region of
                         sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
                         [,digit] will convert the domain value to number, otherwise, string
                         e.g. R4B-1250A_S16_counts.txt with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
                         will return SequencingSample.metadata = {
                                              &#39;exp_rep&#39;: &#39;B&#39;,
                                              &#39;concentration&#39;: 1250.0,
                                              &#39;seq_rep&#39;: &#39;A&#39;,
                                              &#39;id&#39;: 16.0
                                           }
    :param sort_fn: optional, callable to sort sample order
    :param black_list: name of sample files that will be excluded in loading
    :param slient: boolean, false: print calculation progress to the screen
    :return: sample_set: a list of SequencingSample class
    &#34;&#34;&#34;
    if sample_list is None:
        sample_list = get_file_list(file_root=file_root, pattern=pattern)
        print(&#34;NOTICE: no sample_list is given, samples will extract automaticall from file_root.&#34;)
        if type(x_values) != str:
            raise Exception(&#34;No sample_list is given, please indicate domain name instead of list of real values to extract x_values&#34;)
    sample_set = []
    if type(x_values) == str:
        x_values = [x_values for _ in sample_list]
    for sample_ix,sample_name in enumerate(sample_list):
        if sample_name not in black_list:
            sample = SequencingSample(file_root=file_root,
                                      sample_name=sample_name,
                                      x_value=x_values[sample_ix],
                                      name_pattern=name_pattern,
                                      silent=silent)
            sample_set.append(sample)
    if sort_fn:
        sample_set.sort(key=sort_fn)
    return sample_set</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="k_seq.data.pre_processing.SequenceSet"><code class="flex name class">
<span>class <span class="ident">SequenceSet</span></span>
</code></dt>
<dd>
<section class="desc"><p>This class containing the dataset of valid sequences aligned from a list of SequencingSample</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class SequenceSet:
    &#34;&#34;&#34;
    This class containing the dataset of valid sequences aligned from a list of SequencingSample
    &#34;&#34;&#34;

    def __init__(self, sample_set, remove_spike_in=True, note=None):
        &#34;&#34;&#34;
        Convert a list of SequencingSample objects to a SequenceSet object. A typical SequenceSet object includes:
            self.input_seq_num: number of unique sequences in all &#34;input&#34; samples
            self.reacted_seq_num number of unique sequences in all &#34;reacted&#34; samples
            self.valid_seq_num: number of valid unqiue sequences that detected in at least one &#34;input&#34; sample and one
                                &#34;reacted&#34; sample
            self.sample_info: a list of dictionaries, containing the information from original samples
            self.count_table: a pandas.DataFrame object of valid sequences and their original counts in samples
            self.valid_seq_remove_spike_in: Boolean. If True, sequences considered as spike-in will not include in counting
            self.note: Optional. Addtional notes regarding to the dataset
        :param sample_set: a list of SequencingSample objects to convert
        :param remove_spike_in: Boolean. See above
        :param note: Optional. See above
        :return: A SequenceSet object
        &#34;&#34;&#34;
        import datetime
        import Levenshtein

        # find valid sequence set
        input_seq_set = set()
        reacted_seq_set = set()

        if remove_spike_in:
            for sample in sample_set:
                if sample.sample_type == &#39;input&#39;:
                    input_seq_set.update([
                        seq for seq in sample.sequences.keys()
                        if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                    ])
                elif sample.sample_type == &#39;reacted&#39;:
                    reacted_seq_set.update([
                        seq for seq in sample.sequences.keys()
                        if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                    ])
        else:
            for sample in sample_set:
                if sample.sample_type == &#39;input&#39;:
                    input_seq_set.update(list(sample.sequences.keys()))
                elif sample.sample_type == &#39;reacted&#39;:
                    reacted_seq_set.update(list(sample.sequences.keys()))

        valid_set = input_seq_set &amp; reacted_seq_set
        self.dataset_info = {
            &#39;input_seq_num&#39;: len(input_seq_set),
            &#39;reacted_seq_num&#39;: len(reacted_seq_set),
            &#39;valid_seq_num&#39;: len(valid_set),
            &#39;remove_spike_in&#39;: remove_spike_in
        }
        if note:
            self.dataset_info[&#39;note&#39;] = note

        # preserve sample info
        self.sample_info = {}
        for sample in sample_set:
            sample_info_dict = sample.__dict__.copy()
            sequences = sample_info_dict.pop(&#39;sequences&#39;, None)
            self.sample_info[sample.name] = {
                &#39;valid_seqs_num&#39;: np.sum([1 for seq in sequences.keys() if seq in valid_set]),
                &#39;valid_seqs_counts&#39;: np.sum([seq[1] for seq in sequences.items() if seq[0] in valid_set])
            }
            self.sample_info[sample.name].update(sample_info_dict)

        # create valid sequence table
        self.count_table = pd.DataFrame(index=list(valid_set), columns=[sample.name for sample in sample_set])
        for seq in valid_set:
            for sample in sample_set:
                if seq in sample.sequences.keys():
                    self.count_table.loc[seq, sample.name] = sample.sequences[seq]

        self.dataset_info[&#39;timestamp&#39;] = str(datetime.datetime.now())

    def get_reacted_frac(self, input_average=&#39;median&#39;, black_list=None, inplace=True):

        if not black_list:
            black_list = []
        input_samples = [sample[0] for sample in self.sample_info.items()
                         if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;input&#39;]
        reacted_samples = [sample[0] for sample in self.sample_info.items()
                           if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;reacted&#39;]
        reacted_frac_table = pd.DataFrame(index=self.count_table.index, columns=reacted_samples)
        reacted_frac_table.input_avg_type = input_average
        reacted_frac_table.col_x_values = [self.sample_info[sample][&#39;x_value&#39;] for sample in reacted_frac_table.columns]

        if input_average == &#39;median&#39;:
            input_amount_avg = np.nanmedian(np.array([
                list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                self.sample_info[sample][&#39;quant_factor&#39;])
                for sample in input_samples
            ]), axis=0)
        elif input_average == &#39;mean&#39;:
            input_amount_avg = np.nanmean(np.array([
                list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                     self.sample_info[sample][&#39;quant_factor&#39;])
                for sample in input_samples
            ]), axis=0)
        else:
            raise Exception(&#34;Error: input_average should be &#39;median&#39; or &#39;mean&#39;&#34;)

        reacted_frac_table.input_avg = input_amount_avg
        for sample in reacted_samples:
            reacted_frac_table[sample] = (
                self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                self.sample_info[sample][&#39;quant_factor&#39;]
            )/reacted_frac_table.input_avg

        if inplace:
            self.reacted_frac_table = reacted_frac_table
        else:
            return reacted_frac_table</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="k_seq.data.pre_processing.SequenceSet.__init__"><code class="name flex">
<span>def <span class="ident">__init__</span></span>(<span>self, sample_set, remove_spike_in=True, note=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Convert a list of SequencingSample objects to a SequenceSet object. A typical SequenceSet object includes:
self.input_seq_num: number of unique sequences in all "input" samples
self.reacted_seq_num number of unique sequences in all "reacted" samples
self.valid_seq_num: number of valid unqiue sequences that detected in at least one "input" sample and one
"reacted" sample
self.sample_info: a list of dictionaries, containing the information from original samples
self.count_table: a pandas.DataFrame object of valid sequences and their original counts in samples
self.valid_seq_remove_spike_in: Boolean. If True, sequences considered as spike-in will not include in counting
self.note: Optional. Addtional notes regarding to the dataset
:param sample_set: a list of SequencingSample objects to convert
:param remove_spike_in: Boolean. See above
:param note: Optional. See above
:return: A SequenceSet object</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def __init__(self, sample_set, remove_spike_in=True, note=None):
    &#34;&#34;&#34;
    Convert a list of SequencingSample objects to a SequenceSet object. A typical SequenceSet object includes:
        self.input_seq_num: number of unique sequences in all &#34;input&#34; samples
        self.reacted_seq_num number of unique sequences in all &#34;reacted&#34; samples
        self.valid_seq_num: number of valid unqiue sequences that detected in at least one &#34;input&#34; sample and one
                            &#34;reacted&#34; sample
        self.sample_info: a list of dictionaries, containing the information from original samples
        self.count_table: a pandas.DataFrame object of valid sequences and their original counts in samples
        self.valid_seq_remove_spike_in: Boolean. If True, sequences considered as spike-in will not include in counting
        self.note: Optional. Addtional notes regarding to the dataset
    :param sample_set: a list of SequencingSample objects to convert
    :param remove_spike_in: Boolean. See above
    :param note: Optional. See above
    :return: A SequenceSet object
    &#34;&#34;&#34;
    import datetime
    import Levenshtein

    # find valid sequence set
    input_seq_set = set()
    reacted_seq_set = set()

    if remove_spike_in:
        for sample in sample_set:
            if sample.sample_type == &#39;input&#39;:
                input_seq_set.update([
                    seq for seq in sample.sequences.keys()
                    if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                ])
            elif sample.sample_type == &#39;reacted&#39;:
                reacted_seq_set.update([
                    seq for seq in sample.sequences.keys()
                    if Levenshtein.distance(seq, sample.spike_in[&#39;spike_in&#39;]) &gt; sample.spike_in[&#39;quant_factor_max_dist&#39;]
                ])
    else:
        for sample in sample_set:
            if sample.sample_type == &#39;input&#39;:
                input_seq_set.update(list(sample.sequences.keys()))
            elif sample.sample_type == &#39;reacted&#39;:
                reacted_seq_set.update(list(sample.sequences.keys()))

    valid_set = input_seq_set &amp; reacted_seq_set
    self.dataset_info = {
        &#39;input_seq_num&#39;: len(input_seq_set),
        &#39;reacted_seq_num&#39;: len(reacted_seq_set),
        &#39;valid_seq_num&#39;: len(valid_set),
        &#39;remove_spike_in&#39;: remove_spike_in
    }
    if note:
        self.dataset_info[&#39;note&#39;] = note

    # preserve sample info
    self.sample_info = {}
    for sample in sample_set:
        sample_info_dict = sample.__dict__.copy()
        sequences = sample_info_dict.pop(&#39;sequences&#39;, None)
        self.sample_info[sample.name] = {
            &#39;valid_seqs_num&#39;: np.sum([1 for seq in sequences.keys() if seq in valid_set]),
            &#39;valid_seqs_counts&#39;: np.sum([seq[1] for seq in sequences.items() if seq[0] in valid_set])
        }
        self.sample_info[sample.name].update(sample_info_dict)

    # create valid sequence table
    self.count_table = pd.DataFrame(index=list(valid_set), columns=[sample.name for sample in sample_set])
    for seq in valid_set:
        for sample in sample_set:
            if seq in sample.sequences.keys():
                self.count_table.loc[seq, sample.name] = sample.sequences[seq]

    self.dataset_info[&#39;timestamp&#39;] = str(datetime.datetime.now())</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.SequenceSet.get_reacted_frac"><code class="name flex">
<span>def <span class="ident">get_reacted_frac</span></span>(<span>self, input_average=&#39;median&#39;, black_list=None, inplace=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_reacted_frac(self, input_average=&#39;median&#39;, black_list=None, inplace=True):

    if not black_list:
        black_list = []
    input_samples = [sample[0] for sample in self.sample_info.items()
                     if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;input&#39;]
    reacted_samples = [sample[0] for sample in self.sample_info.items()
                       if sample[0] not in black_list and sample[1][&#39;sample_type&#39;] == &#39;reacted&#39;]
    reacted_frac_table = pd.DataFrame(index=self.count_table.index, columns=reacted_samples)
    reacted_frac_table.input_avg_type = input_average
    reacted_frac_table.col_x_values = [self.sample_info[sample][&#39;x_value&#39;] for sample in reacted_frac_table.columns]

    if input_average == &#39;median&#39;:
        input_amount_avg = np.nanmedian(np.array([
            list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
            self.sample_info[sample][&#39;quant_factor&#39;])
            for sample in input_samples
        ]), axis=0)
    elif input_average == &#39;mean&#39;:
        input_amount_avg = np.nanmean(np.array([
            list(self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
                 self.sample_info[sample][&#39;quant_factor&#39;])
            for sample in input_samples
        ]), axis=0)
    else:
        raise Exception(&#34;Error: input_average should be &#39;median&#39; or &#39;mean&#39;&#34;)

    reacted_frac_table.input_avg = input_amount_avg
    for sample in reacted_samples:
        reacted_frac_table[sample] = (
            self.count_table[sample] / self.sample_info[sample][&#39;total_counts&#39;] *
            self.sample_info[sample][&#39;quant_factor&#39;]
        )/reacted_frac_table.input_avg

    if inplace:
        self.reacted_frac_table = reacted_frac_table
    else:
        return reacted_frac_table</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="k_seq.data.pre_processing.SequencingSample"><code class="flex name class">
<span>class <span class="ident">SequencingSample</span></span>
</code></dt>
<dd>
<section class="desc"><p>This class defines and describe the experimental samples sequenced in k-seq experiments</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class SequencingSample:

    &#34;&#34;&#34;
    This class defines and describe the experimental samples sequenced in k-seq experiments
    &#34;&#34;&#34;

    def __init__(self, file_root, sample_name, x_value, silent=True, name_pattern=None):
        &#34;&#34;&#34;
        initialize a SequencingSample instance by reading single count file
        :param file_root: root directory of the sample folder
        :param sample_name: the name (without directory) of the sample
        :param corresponding x_value for the sample. If string, will automatically inspect the domain with the name
        :param silent: [Optional] boolean.
        :param name_pattern: optional. pattern to extract metadata. pattern rules: [...] to include the region of
               sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
               [,digit] will convert the domain value to float in applicable, otherwise, string
               e.g. R4B-1250A_S16_counts.txt with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
               will return SequencingSample.metadata = {
                                    &#39;exp_rep&#39;: &#39;B&#39;,
                                    &#39;concentration&#39;: 1250.0,
                                    &#39;seq_rep&#39;: &#39;A&#39;,
                                    &#39;id&#39;: 16.0
                                 }
        &#34;&#34;&#34;
        import datetime

        self.metadata = {}
        if file_root[-1] != &#39;/&#39;:
            file_root += &#39;/&#39;
        self.metadata[&#39;file_dirc&#39;] = &#39;{}{}&#39;.format(file_root, sample_name)
        self.unique_seqs, self.total_counts, self.sequences = io.read_count_file(self.metadata[&#39;file_dirc&#39;])

        if name_pattern:
            metadata = extract_sample_metadata(sample_name=sample_name, name_pattern=name_pattern)
            self.name = metadata.pop(&#39;name&#39;, None)
            self.metadata.update(metadata)
        else:
            self.name = sample_name

        if &#39;input&#39; in self.name or &#39;Input&#39; in self.name:
            self.sample_type = &#39;input&#39;
        else:
            self.sample_type = &#39;reacted&#39;

        if self.sample_type == &#39;input&#39;:
            self.x_value = np.nan
        else:
            if type(x_value) == str:
                self.x_value = self.metadata[x_value]
            else:
                self.x_value = x_value

        self.metadata[&#39;timestamp&#39;] = str(datetime.datetime.now())
        if not silent:
            print(&#34;Sample {} imported.&#34;.format(self.name))

    def survey_spike_in(self, spike_in, max_dist_to_survey=10, silent=True):
        &#34;&#34;&#34;
        This method will survey the number of spike-in sequences in the sample, with edit distance to the center
        spike-in sequence
        Following attributes will be added to the instance:
        - spike_in: dict, {
            spike_in_counts: list of int with length max_dist_to_survey + 1, number of total counts with distance i to
                             the center spike-in sequence
            spike_in: string, spike_in sequence
          }
        :param spike_in: string, the sequence of spike-in, consider as the center sequence
        :param max_dist_to_survey: int, the maximum distance to survey
        :return: None
        &#34;&#34;&#34;
        import Levenshtein

        self.spike_in = {}
        self.spike_in[&#39;spike_in_counts&#39;] = np.array([0 for _ in range(max_dist_to_survey + 1)])
        self.spike_in[&#39;spike_in&#39;] = spike_in
        for seq in self.sequences.keys():
            dist = Levenshtein.distance(spike_in, seq)
            if dist &lt;= max_dist_to_survey:
                self.spike_in[&#39;spike_in_counts&#39;][dist] += self.sequences[seq]
        if not silent:
            print(&#34;Survey spike-in counts for sample {}. Done.&#34;.format(self.name))

    def get_quant_factor(self, spike_in_amount, max_dist=0, silent=True):
        &#34;&#34;&#34;
        Add quant_factor and quant_factor_max_dist attributes to SequencingSample
        quant_factor here is defined as spike_in_amount/total_counts/np.sum(spike_in_counts[:max_dist + 1])
        :param max_dist:
        :param spike_in_amount:
        :return:
        &#34;&#34;&#34;

        self.quant_factor = spike_in_amount * self.total_counts / np.sum(self.spike_in[&#39;spike_in_counts&#39;][:max_dist + 1])
        self.spike_in[&#39;quant_factor_max_dist&#39;] = max_dist
        self.spike_in[&#39;spike_in_amount&#39;] = spike_in_amount

        if not silent:
            print(&#34;Calculate quant-factor for sample {}. Done.&#34;.format(self.name))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="k_seq.data.pre_processing.SequencingSample.__init__"><code class="name flex">
<span>def <span class="ident">__init__</span></span>(<span>self, file_root, sample_name, x_value, silent=True, name_pattern=None)</span>
</code></dt>
<dd>
<section class="desc"><p>initialize a SequencingSample instance by reading single count file
:param file_root: root directory of the sample folder
:param sample_name: the name (without directory) of the sample
:param corresponding x_value for the sample. If string, will automatically inspect the domain with the name
:param silent: [Optional] boolean.
:param name_pattern: optional. pattern to extract metadata. pattern rules: [&hellip;] to include the region of
sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
[,digit] will convert the domain value to float in applicable, otherwise, string
e.g. R4B-1250A_S16_counts.txt with pattern = "R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt"
will return SequencingSample.metadata = {
'exp_rep': 'B',
'concentration': 1250.0,
'seq_rep': 'A',
'id': 16.0
}</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def __init__(self, file_root, sample_name, x_value, silent=True, name_pattern=None):
    &#34;&#34;&#34;
    initialize a SequencingSample instance by reading single count file
    :param file_root: root directory of the sample folder
    :param sample_name: the name (without directory) of the sample
    :param corresponding x_value for the sample. If string, will automatically inspect the domain with the name
    :param silent: [Optional] boolean.
    :param name_pattern: optional. pattern to extract metadata. pattern rules: [...] to include the region of
           sample_name, {domain_name[, digit]} to indicate region of domain to extract as metadata, including
           [,digit] will convert the domain value to float in applicable, otherwise, string
           e.g. R4B-1250A_S16_counts.txt with pattern = &#34;R4[{exp_rep}-{concentration, digit}{seq_rep}_S{id, digit}_counts.txt&#34;
           will return SequencingSample.metadata = {
                                &#39;exp_rep&#39;: &#39;B&#39;,
                                &#39;concentration&#39;: 1250.0,
                                &#39;seq_rep&#39;: &#39;A&#39;,
                                &#39;id&#39;: 16.0
                             }
    &#34;&#34;&#34;
    import datetime

    self.metadata = {}
    if file_root[-1] != &#39;/&#39;:
        file_root += &#39;/&#39;
    self.metadata[&#39;file_dirc&#39;] = &#39;{}{}&#39;.format(file_root, sample_name)
    self.unique_seqs, self.total_counts, self.sequences = io.read_count_file(self.metadata[&#39;file_dirc&#39;])

    if name_pattern:
        metadata = extract_sample_metadata(sample_name=sample_name, name_pattern=name_pattern)
        self.name = metadata.pop(&#39;name&#39;, None)
        self.metadata.update(metadata)
    else:
        self.name = sample_name

    if &#39;input&#39; in self.name or &#39;Input&#39; in self.name:
        self.sample_type = &#39;input&#39;
    else:
        self.sample_type = &#39;reacted&#39;

    if self.sample_type == &#39;input&#39;:
        self.x_value = np.nan
    else:
        if type(x_value) == str:
            self.x_value = self.metadata[x_value]
        else:
            self.x_value = x_value

    self.metadata[&#39;timestamp&#39;] = str(datetime.datetime.now())
    if not silent:
        print(&#34;Sample {} imported.&#34;.format(self.name))</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.SequencingSample.get_quant_factor"><code class="name flex">
<span>def <span class="ident">get_quant_factor</span></span>(<span>self, spike_in_amount, max_dist=0, silent=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Add quant_factor and quant_factor_max_dist attributes to SequencingSample
quant_factor here is defined as spike_in_amount/total_counts/np.sum(spike_in_counts[:max_dist + 1])
:param max_dist:
:param spike_in_amount:
:return:</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_quant_factor(self, spike_in_amount, max_dist=0, silent=True):
    &#34;&#34;&#34;
    Add quant_factor and quant_factor_max_dist attributes to SequencingSample
    quant_factor here is defined as spike_in_amount/total_counts/np.sum(spike_in_counts[:max_dist + 1])
    :param max_dist:
    :param spike_in_amount:
    :return:
    &#34;&#34;&#34;

    self.quant_factor = spike_in_amount * self.total_counts / np.sum(self.spike_in[&#39;spike_in_counts&#39;][:max_dist + 1])
    self.spike_in[&#39;quant_factor_max_dist&#39;] = max_dist
    self.spike_in[&#39;spike_in_amount&#39;] = spike_in_amount

    if not silent:
        print(&#34;Calculate quant-factor for sample {}. Done.&#34;.format(self.name))</code></pre>
</details>
</dd>
<dt id="k_seq.data.pre_processing.SequencingSample.survey_spike_in"><code class="name flex">
<span>def <span class="ident">survey_spike_in</span></span>(<span>self, spike_in, max_dist_to_survey=10, silent=True)</span>
</code></dt>
<dd>
<section class="desc"><p>This method will survey the number of spike-in sequences in the sample, with edit distance to the center
spike-in sequence
Following attributes will be added to the instance:
- spike_in: dict, {
spike_in_counts: list of int with length max_dist_to_survey + 1, number of total counts with distance i to
the center spike-in sequence
spike_in: string, spike_in sequence
}
:param spike_in: string, the sequence of spike-in, consider as the center sequence
:param max_dist_to_survey: int, the maximum distance to survey
:return: None</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def survey_spike_in(self, spike_in, max_dist_to_survey=10, silent=True):
    &#34;&#34;&#34;
    This method will survey the number of spike-in sequences in the sample, with edit distance to the center
    spike-in sequence
    Following attributes will be added to the instance:
    - spike_in: dict, {
        spike_in_counts: list of int with length max_dist_to_survey + 1, number of total counts with distance i to
                         the center spike-in sequence
        spike_in: string, spike_in sequence
      }
    :param spike_in: string, the sequence of spike-in, consider as the center sequence
    :param max_dist_to_survey: int, the maximum distance to survey
    :return: None
    &#34;&#34;&#34;
    import Levenshtein

    self.spike_in = {}
    self.spike_in[&#39;spike_in_counts&#39;] = np.array([0 for _ in range(max_dist_to_survey + 1)])
    self.spike_in[&#39;spike_in&#39;] = spike_in
    for seq in self.sequences.keys():
        dist = Levenshtein.distance(spike_in, seq)
        if dist &lt;= max_dist_to_survey:
            self.spike_in[&#39;spike_in_counts&#39;][dist] += self.sequences[seq]
    if not silent:
        print(&#34;Survey spike-in counts for sample {}. Done.&#34;.format(self.name))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="k_seq.data" href="index.html">k_seq.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="k_seq.data.pre_processing.extract_sample_metadata" href="#k_seq.data.pre_processing.extract_sample_metadata">extract_sample_metadata</a></code></li>
<li><code><a title="k_seq.data.pre_processing.get_file_list" href="#k_seq.data.pre_processing.get_file_list">get_file_list</a></code></li>
<li><code><a title="k_seq.data.pre_processing.get_quant_factors" href="#k_seq.data.pre_processing.get_quant_factors">get_quant_factors</a></code></li>
<li><code><a title="k_seq.data.pre_processing.load_count_files" href="#k_seq.data.pre_processing.load_count_files">load_count_files</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="k_seq.data.pre_processing.SequenceSet" href="#k_seq.data.pre_processing.SequenceSet">SequenceSet</a></code></h4>
<ul class="">
<li><code><a title="k_seq.data.pre_processing.SequenceSet.__init__" href="#k_seq.data.pre_processing.SequenceSet.__init__">__init__</a></code></li>
<li><code><a title="k_seq.data.pre_processing.SequenceSet.get_reacted_frac" href="#k_seq.data.pre_processing.SequenceSet.get_reacted_frac">get_reacted_frac</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="k_seq.data.pre_processing.SequencingSample" href="#k_seq.data.pre_processing.SequencingSample">SequencingSample</a></code></h4>
<ul class="">
<li><code><a title="k_seq.data.pre_processing.SequencingSample.__init__" href="#k_seq.data.pre_processing.SequencingSample.__init__">__init__</a></code></li>
<li><code><a title="k_seq.data.pre_processing.SequencingSample.get_quant_factor" href="#k_seq.data.pre_processing.SequencingSample.get_quant_factor">get_quant_factor</a></code></li>
<li><code><a title="k_seq.data.pre_processing.SequencingSample.survey_spike_in" href="#k_seq.data.pre_processing.SequencingSample.survey_spike_in">survey_spike_in</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>